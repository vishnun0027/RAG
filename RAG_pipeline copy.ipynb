{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Build a Retrieval Augmented Generation (RAG) App"]},{"cell_type":"markdown","metadata":{},"source":["# ChatMistralAI, langchain, FAISS "]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-17T08:36:23.070926Z","iopub.status.busy":"2024-07-17T08:36:23.070658Z","iopub.status.idle":"2024-07-17T08:36:23.075506Z","shell.execute_reply":"2024-07-17T08:36:23.074582Z","shell.execute_reply.started":"2024-07-17T08:36:23.070901Z"},"trusted":true},"outputs":[],"source":["# ! pip install langchain \n","# ! pip install langchain_community langchain_chroma\n","# ! pip install langchain-mistralai\n","# ! pip install sentence_transformers \n","# ! pip install -U langchain-huggingface\n","# !pip install sentence_transformers==2.4.0 --quiet\n","# !pip install unstructured --quiet\n","# !pip install pdf2image --quiet\n","# !pip install pdfminer.six==20221105 --quiet\n","# !pip install unstructured-inference --quiet\n","# !pip install pikepdf==8.13.0 --quiet\n","# !pip install pypdf==4.0.2 --quiet\n","# !pip install pillow_heif==0.15.0 --quiet"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\nvish\\AppData\\Local\\Temp\\ipykernel_16164\\3469481355.py:12: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  from tqdm.autonotebook import tqdm, trange\n"]},{"data":{"text/plain":["True"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import os \n","from dotenv import load_dotenv\n","from langchain_mistralai import ChatMistralAI\n","from langchain_huggingface import HuggingFaceEmbeddings\n","from langchain_community.document_loaders import DirectoryLoader\n","from langchain.vectorstores.utils import filter_complex_metadata\n","from langchain_text_splitters import RecursiveCharacterTextSplitter\n","from langchain.vectorstores.chroma import Chroma\n","from langchain_core.runnables import RunnablePassthrough\n","from langchain_core.prompts import PromptTemplate\n","from langchain_core.output_parsers import StrOutputParser\n","from tqdm.autonotebook import tqdm, trange\n","\n","# Load environment variables\n","load_dotenv()\n"]},{"cell_type":"markdown","metadata":{},"source":["**using ChatMistralAI mistral-large-latest model**"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T08:36:47.106956Z","iopub.status.busy":"2024-07-17T08:36:47.106596Z","iopub.status.idle":"2024-07-17T08:37:00.340620Z","shell.execute_reply":"2024-07-17T08:37:00.339655Z","shell.execute_reply.started":"2024-07-17T08:36:47.106922Z"},"trusted":true},"outputs":[],"source":["llm = ChatMistralAI(model=\"mistral-large-latest\")"]},{"cell_type":"markdown","metadata":{},"source":["**using HuggingFaceEmbeddings model**"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T08:37:00.344326Z","iopub.status.busy":"2024-07-17T08:37:00.343579Z","iopub.status.idle":"2024-07-17T08:37:08.992779Z","shell.execute_reply":"2024-07-17T08:37:08.991658Z","shell.execute_reply.started":"2024-07-17T08:37:00.344286Z"},"trusted":true},"outputs":[],"source":["embeddings = HuggingFaceEmbeddings()"]},{"cell_type":"markdown","metadata":{},"source":["**load Document/data**"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of documents loaded: 1\n"]}],"source":["# Use Directory Loader to load documents\n","loader = DirectoryLoader(\"documents\", glob=\"**/*.pdf\")\n","docs = loader.load()\n","docs = filter_complex_metadata(docs)\n","print(f\"Number of documents loaded: {len(docs)}\")"]},{"cell_type":"markdown","metadata":{},"source":["**Split into chunks**"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T08:37:09.611074Z","iopub.status.busy":"2024-07-17T08:37:09.610710Z","iopub.status.idle":"2024-07-17T08:37:09.629172Z","shell.execute_reply":"2024-07-17T08:37:09.628185Z","shell.execute_reply.started":"2024-07-17T08:37:09.611039Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["51\n"]}],"source":["text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n","splits = text_splitter.split_documents(docs)\n","print(len(splits))\n"]},{"cell_type":"markdown","metadata":{},"source":["**vectorstores (chromadb)**"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T08:37:09.630418Z","iopub.status.busy":"2024-07-17T08:37:09.630119Z","iopub.status.idle":"2024-07-17T08:37:11.146086Z","shell.execute_reply":"2024-07-17T08:37:11.145071Z","shell.execute_reply.started":"2024-07-17T08:37:09.630394Z"},"trusted":true},"outputs":[],"source":["vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)"]},{"cell_type":"markdown","metadata":{},"source":["**Retrieval and Generation**"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T08:38:50.066687Z","iopub.status.busy":"2024-07-17T08:38:50.065979Z","iopub.status.idle":"2024-07-17T08:38:50.272121Z","shell.execute_reply":"2024-07-17T08:38:50.271285Z","shell.execute_reply.started":"2024-07-17T08:38:50.066648Z"},"trusted":true},"outputs":[],"source":["def format_docs(docs):\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)"]},{"cell_type":"markdown","metadata":{},"source":["### Customizing the prompt"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# Retrieve \n","retriever = vectorstore.as_retriever()"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T08:40:12.207161Z","iopub.status.busy":"2024-07-17T08:40:12.206156Z","iopub.status.idle":"2024-07-17T08:40:12.213715Z","shell.execute_reply":"2024-07-17T08:40:12.212788Z","shell.execute_reply.started":"2024-07-17T08:40:12.207117Z"},"trusted":true},"outputs":[],"source":["# Create a prompt template\n","template = \"\"\"only Use the following pieces of context to answer the question at the end.\n","            only Use the following pieces of retrieved context to answer\n","            If you don't know the answer from the context, just say that you don't know, don't try to make up an answer.\n","            Use three sentences maximum and keep the answer as concise as possible.\n","            Always say \"thanks for asking!\" at the end of the answer.\n","\n","            {context}\n","\n","            Question: {question}\n","\n","            Helpful Answer:\"\"\"\n","\n","custom_rag_prompt = PromptTemplate.from_template(template)\n","\n","rag_chain = (\n","    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n","    | custom_rag_prompt\n","    | llm\n","    | StrOutputParser()\n",")\n","\n"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T08:42:21.045827Z","iopub.status.busy":"2024-07-17T08:42:21.044816Z","iopub.status.idle":"2024-07-17T08:42:23.619789Z","shell.execute_reply":"2024-07-17T08:42:23.618788Z","shell.execute_reply.started":"2024-07-17T08:42:21.045792Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Self-attention, also known as intra-attention, is a mechanism that relates different positions of a\n","single sequence to compute a representation of the sequence. It is used in various tasks such as\n","reading comprehension, abstractive summarization, textual entailment, and learning task-independent\n","sentence representations. The Transformer model, which relies entirely on self-attention, uses it to\n","compute representations of its input and output without using sequence-aligned RNNs or convolution.\n","Thanks for asking!\n"]}],"source":["from textwrap import fill\n","answer =  rag_chain.invoke(\"What is Self-attention is a mechanism and what is used for?\")\n","print(fill(answer, width=100))"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["I'm sorry for the confusion, but the context provided does not contain any information about an\n","entity named \"llama 2\". Therefore, I'm unable to provide the advantages of llama 2. Thanks for\n","asking!\n"]}],"source":["answer =  rag_chain.invoke(\"What is aduvantages of llama 2?\")\n","print(fill(answer, width=100))"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":4}
