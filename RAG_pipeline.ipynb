{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Build a Retrieval Augmented Generation (RAG) App","metadata":{}},{"cell_type":"markdown","source":"# ChatMistralAI, langchain, FAISS ","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ! pip install langchain langchain_community langchain_chroma\n# ! pip install -U langchain-community faiss-cpu\n# ! pip install -qU langchain-mistralai\n# ! pip install sentence_transformers --quiet\n# !pip install langchainhub","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-17T08:36:23.070658Z","iopub.execute_input":"2024-07-17T08:36:23.070926Z","iopub.status.idle":"2024-07-17T08:36:23.075506Z","shell.execute_reply.started":"2024-07-17T08:36:23.070901Z","shell.execute_reply":"2024-07-17T08:36:23.074582Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import getpass\nimport os\n\nos.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\nos.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()","metadata":{"execution":{"iopub.status.busy":"2024-07-17T08:36:23.076546Z","iopub.execute_input":"2024-07-17T08:36:23.076823Z","iopub.status.idle":"2024-07-17T08:36:47.105093Z","shell.execute_reply.started":"2024-07-17T08:36:23.076798Z","shell.execute_reply":"2024-07-17T08:36:47.104333Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdin","text":" ···················································\n"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"## using ChatMistralAI mistral-large-latest model","metadata":{}},{"cell_type":"code","source":"import getpass\nimport os\n\nos.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n\nfrom langchain_mistralai import ChatMistralAI\n\nllm = ChatMistralAI(model=\"mistral-large-latest\")","metadata":{"execution":{"iopub.status.busy":"2024-07-17T08:36:47.106596Z","iopub.execute_input":"2024-07-17T08:36:47.106956Z","iopub.status.idle":"2024-07-17T08:37:00.340620Z","shell.execute_reply.started":"2024-07-17T08:36:47.106922Z","shell.execute_reply":"2024-07-17T08:37:00.339655Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdin","text":" ································\n"}]},{"cell_type":"markdown","source":"## using HuggingFaceEmbeddings model","metadata":{}},{"cell_type":"code","source":"from langchain.embeddings import HuggingFaceEmbeddings\n\nembeddings = HuggingFaceEmbeddings()","metadata":{"execution":{"iopub.status.busy":"2024-07-17T08:37:00.343579Z","iopub.execute_input":"2024-07-17T08:37:00.344326Z","iopub.status.idle":"2024-07-17T08:37:08.992779Z","shell.execute_reply.started":"2024-07-17T08:37:00.344286Z","shell.execute_reply":"2024-07-17T08:37:08.991658Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n  warn_deprecated(\n/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n  from tqdm.autonotebook import tqdm, trange\n2024-07-17 08:37:03.734069: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-17 08:37:03.734126: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-17 08:37:03.735578: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## load Document/data","metadata":{}},{"cell_type":"code","source":"import bs4\nfrom langchain_community.document_loaders import WebBaseLoader\nfrom langchain_core.output_parsers import StrOutputParser\n\n# Load, chunk and index the contents of the blog.\nloader = WebBaseLoader(\n    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n    bs_kwargs=dict(\n        parse_only=bs4.SoupStrainer(\n            class_=(\"post-content\", \"post-title\", \"post-header\")\n        )\n    ),\n)\ndocs = loader.load()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-17T08:37:08.993979Z","iopub.execute_input":"2024-07-17T08:37:08.994773Z","iopub.status.idle":"2024-07-17T08:37:09.603638Z","shell.execute_reply.started":"2024-07-17T08:37:08.994744Z","shell.execute_reply":"2024-07-17T08:37:09.602618Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Split into chunks","metadata":{}},{"cell_type":"code","source":"from langchain_text_splitters import RecursiveCharacterTextSplitter\ntext_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\nsplits = text_splitter.split_documents(docs)\nprint(len(splits))\n","metadata":{"execution":{"iopub.status.busy":"2024-07-17T08:37:09.610710Z","iopub.execute_input":"2024-07-17T08:37:09.611074Z","iopub.status.idle":"2024-07-17T08:37:09.629172Z","shell.execute_reply.started":"2024-07-17T08:37:09.611039Z","shell.execute_reply":"2024-07-17T08:37:09.628185Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"66\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## vectorstores (Faiss,chromadb,pinecone)","metadata":{}},{"cell_type":"code","source":"from langchain_community.vectorstores import FAISS\nvectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-17T08:37:09.630119Z","iopub.execute_input":"2024-07-17T08:37:09.630418Z","iopub.status.idle":"2024-07-17T08:37:11.146086Z","shell.execute_reply.started":"2024-07-17T08:37:09.630394Z","shell.execute_reply":"2024-07-17T08:37:11.145071Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Retrieval and Generation","metadata":{}},{"cell_type":"code","source":"from langchain import hub\nfrom langchain_core.runnables import RunnablePassthrough\n\n# Retrieve and generate using the relevant snippets of the blog.\nretriever = vectorstore.as_retriever()\nprompt = hub.pull(\"rlm/rag-prompt\")\n\n\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n\nrag_chain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-17T08:38:50.065979Z","iopub.execute_input":"2024-07-17T08:38:50.066687Z","iopub.status.idle":"2024-07-17T08:38:50.272121Z","shell.execute_reply.started":"2024-07-17T08:38:50.066648Z","shell.execute_reply":"2024-07-17T08:38:50.271285Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"rag_chain.invoke(\"What is Task Decomposition?\")","metadata":{"execution":{"iopub.status.busy":"2024-07-17T08:38:57.301292Z","iopub.execute_input":"2024-07-17T08:38:57.302198Z","iopub.status.idle":"2024-07-17T08:39:00.387316Z","shell.execute_reply.started":"2024-07-17T08:38:57.302162Z","shell.execute_reply":"2024-07-17T08:39:00.386312Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"'Task decomposition is the process of breaking down a complex problem or task into smaller, more manageable parts or subtasks. This can be achieved in several ways, such as by using a language model with simple prompting, task-specific instructions, or human inputs. For instance, in writing a novel, the task can be decomposed by creating a story outline. The execution of these subtasks is then carried out by expert models, which log the results for further analysis and inference. However, task decomposition and long-term planning can be challenging due to the limited context length and the difficulty in adjusting plans when faced with unexpected errors.'"},"metadata":{}}]},{"cell_type":"markdown","source":"### Customizing the prompt","metadata":{}},{"cell_type":"code","source":"from langchain_core.prompts import PromptTemplate\n\ntemplate = \"\"\"Use the following pieces of context to answer the question at the end.\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\nUse three sentences maximum and keep the answer as concise as possible.\nAlways say \"thanks for asking!\" at the end of the answer.\n\n{context}\n\nQuestion: {question}\n\nHelpful Answer:\"\"\"\ncustom_rag_prompt = PromptTemplate.from_template(template)\n\nrag_chain = (\n    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n    | custom_rag_prompt\n    | llm\n    | StrOutputParser()\n)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-17T08:40:12.206156Z","iopub.execute_input":"2024-07-17T08:40:12.207161Z","iopub.status.idle":"2024-07-17T08:40:12.213715Z","shell.execute_reply.started":"2024-07-17T08:40:12.207117Z","shell.execute_reply":"2024-07-17T08:40:12.212788Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"rag_chain.invoke(\"What is Self-Reflection brief in two or three sentance?\")","metadata":{"execution":{"iopub.status.busy":"2024-07-17T08:42:21.044816Z","iopub.execute_input":"2024-07-17T08:42:21.045827Z","iopub.status.idle":"2024-07-17T08:42:23.619789Z","shell.execute_reply.started":"2024-07-17T08:42:21.045792Z","shell.execute_reply":"2024-07-17T08:42:23.618788Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"\"Self-reflection in this context is a process where an agent, after determining that its trajectory is inefficient or contains hallucinations, analyzes its failed trajectory and generates ideal reflections to guide future changes in its plan. These reflections are then added to the agent's working memory and used as context for querying the language model, helping the agent to optimize its actions and improve its reasoning skills. Thanks for asking!\""},"metadata":{}}]}]}