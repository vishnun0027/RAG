{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Build a Retrieval Augmented Generation (RAG) App"]},{"cell_type":"markdown","metadata":{},"source":["# ChatMistralAI, langchain, FAISS "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-17T08:36:23.070926Z","iopub.status.busy":"2024-07-17T08:36:23.070658Z","iopub.status.idle":"2024-07-17T08:36:23.075506Z","shell.execute_reply":"2024-07-17T08:36:23.074582Z","shell.execute_reply.started":"2024-07-17T08:36:23.070901Z"},"trusted":true},"outputs":[],"source":["# ! pip install langchain langchain_community langchain_chroma\n","# ! pip install -U langchain-community faiss-cpu\n","# ! pip install -qU langchain-mistralai\n","# ! pip install sentence_transformers --quiet\n","# !pip install langchainhub"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T08:36:23.076823Z","iopub.status.busy":"2024-07-17T08:36:23.076546Z","iopub.status.idle":"2024-07-17T08:36:47.105093Z","shell.execute_reply":"2024-07-17T08:36:47.104333Z","shell.execute_reply.started":"2024-07-17T08:36:23.076798Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" ···················································\n"]}],"source":["import getpass\n","import os\n","\n","os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n","os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["## using ChatMistralAI mistral-large-latest model"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T08:36:47.106956Z","iopub.status.busy":"2024-07-17T08:36:47.106596Z","iopub.status.idle":"2024-07-17T08:37:00.340620Z","shell.execute_reply":"2024-07-17T08:37:00.339655Z","shell.execute_reply.started":"2024-07-17T08:36:47.106922Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" ································\n"]}],"source":["import getpass\n","import os\n","\n","os.environ[\"MISTRAL_API_KEY\"] = getpass.getpass()\n","\n","from langchain_mistralai import ChatMistralAI\n","\n","llm = ChatMistralAI(model=\"mistral-large-latest\")"]},{"cell_type":"markdown","metadata":{},"source":["## using HuggingFaceEmbeddings model"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T08:37:00.344326Z","iopub.status.busy":"2024-07-17T08:37:00.343579Z","iopub.status.idle":"2024-07-17T08:37:08.992779Z","shell.execute_reply":"2024-07-17T08:37:08.991658Z","shell.execute_reply.started":"2024-07-17T08:37:00.344286Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n","  warn_deprecated(\n","/opt/conda/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n","  from tqdm.autonotebook import tqdm, trange\n","2024-07-17 08:37:03.734069: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-07-17 08:37:03.734126: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-07-17 08:37:03.735578: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["from langchain.embeddings import HuggingFaceEmbeddings\n","\n","embeddings = HuggingFaceEmbeddings()"]},{"cell_type":"markdown","metadata":{},"source":["## load Document/data"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T08:37:08.994773Z","iopub.status.busy":"2024-07-17T08:37:08.993979Z","iopub.status.idle":"2024-07-17T08:37:09.603638Z","shell.execute_reply":"2024-07-17T08:37:09.602618Z","shell.execute_reply.started":"2024-07-17T08:37:08.994744Z"},"trusted":true},"outputs":[],"source":["import bs4\n","from langchain_community.document_loaders import WebBaseLoader\n","from langchain_core.output_parsers import StrOutputParser\n","\n","# Load, chunk and index the contents of the blog.\n","loader = WebBaseLoader(\n","    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n","    bs_kwargs=dict(\n","        parse_only=bs4.SoupStrainer(\n","            class_=(\"post-content\", \"post-title\", \"post-header\")\n","        )\n","    ),\n",")\n","docs = loader.load()\n"]},{"cell_type":"markdown","metadata":{},"source":["## Split into chunks"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T08:37:09.611074Z","iopub.status.busy":"2024-07-17T08:37:09.610710Z","iopub.status.idle":"2024-07-17T08:37:09.629172Z","shell.execute_reply":"2024-07-17T08:37:09.628185Z","shell.execute_reply.started":"2024-07-17T08:37:09.611039Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["66\n"]}],"source":["from langchain_text_splitters import RecursiveCharacterTextSplitter\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n","splits = text_splitter.split_documents(docs)\n","print(len(splits))\n"]},{"cell_type":"markdown","metadata":{},"source":["## vectorstores (Faiss,chromadb,pinecone)"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T08:37:09.630418Z","iopub.status.busy":"2024-07-17T08:37:09.630119Z","iopub.status.idle":"2024-07-17T08:37:11.146086Z","shell.execute_reply":"2024-07-17T08:37:11.145071Z","shell.execute_reply.started":"2024-07-17T08:37:09.630394Z"},"trusted":true},"outputs":[],"source":["from langchain_community.vectorstores import FAISS\n","vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)\n"]},{"cell_type":"markdown","metadata":{},"source":["## Retrieval and Generation"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T08:38:50.066687Z","iopub.status.busy":"2024-07-17T08:38:50.065979Z","iopub.status.idle":"2024-07-17T08:38:50.272121Z","shell.execute_reply":"2024-07-17T08:38:50.271285Z","shell.execute_reply.started":"2024-07-17T08:38:50.066648Z"},"trusted":true},"outputs":[],"source":["from langchain import hub\n","from langchain_core.runnables import RunnablePassthrough\n","\n","# Retrieve and generate using the relevant snippets of the blog.\n","retriever = vectorstore.as_retriever()\n","prompt = hub.pull(\"rlm/rag-prompt\")\n","\n","\n","def format_docs(docs):\n","    return \"\\n\\n\".join(doc.page_content for doc in docs)\n","\n","\n","rag_chain = (\n","    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n","    | prompt\n","    | llm\n","    | StrOutputParser()\n",")\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T08:38:57.302198Z","iopub.status.busy":"2024-07-17T08:38:57.301292Z","iopub.status.idle":"2024-07-17T08:39:00.387316Z","shell.execute_reply":"2024-07-17T08:39:00.386312Z","shell.execute_reply.started":"2024-07-17T08:38:57.302162Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'Task decomposition is the process of breaking down a complex problem or task into smaller, more manageable parts or subtasks. This can be achieved in several ways, such as by using a language model with simple prompting, task-specific instructions, or human inputs. For instance, in writing a novel, the task can be decomposed by creating a story outline. The execution of these subtasks is then carried out by expert models, which log the results for further analysis and inference. However, task decomposition and long-term planning can be challenging due to the limited context length and the difficulty in adjusting plans when faced with unexpected errors.'"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["rag_chain.invoke(\"What is Task Decomposition?\")"]},{"cell_type":"markdown","metadata":{},"source":["### Customizing the prompt"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T08:40:12.207161Z","iopub.status.busy":"2024-07-17T08:40:12.206156Z","iopub.status.idle":"2024-07-17T08:40:12.213715Z","shell.execute_reply":"2024-07-17T08:40:12.212788Z","shell.execute_reply.started":"2024-07-17T08:40:12.207117Z"},"trusted":true},"outputs":[],"source":["from langchain_core.prompts import PromptTemplate\n","\n","template = \"\"\"Use the following pieces of context to answer the question at the end.\n","If you don't know the answer, just say that you don't know, don't try to make up an answer.\n","Use three sentences maximum and keep the answer as concise as possible.\n","Always say \"thanks for asking!\" at the end of the answer.\n","\n","{context}\n","\n","Question: {question}\n","\n","Helpful Answer:\"\"\"\n","custom_rag_prompt = PromptTemplate.from_template(template)\n","\n","rag_chain = (\n","    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n","    | custom_rag_prompt\n","    | llm\n","    | StrOutputParser()\n",")\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-07-17T08:42:21.045827Z","iopub.status.busy":"2024-07-17T08:42:21.044816Z","iopub.status.idle":"2024-07-17T08:42:23.619789Z","shell.execute_reply":"2024-07-17T08:42:23.618788Z","shell.execute_reply.started":"2024-07-17T08:42:21.045792Z"},"trusted":true},"outputs":[{"data":{"text/plain":["\"Self-reflection in this context is a process where an agent, after determining that its trajectory is inefficient or contains hallucinations, analyzes its failed trajectory and generates ideal reflections to guide future changes in its plan. These reflections are then added to the agent's working memory and used as context for querying the language model, helping the agent to optimize its actions and improve its reasoning skills. Thanks for asking!\""]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["rag_chain.invoke(\"What is Self-Reflection brief in two or three sentance?\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30747,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
